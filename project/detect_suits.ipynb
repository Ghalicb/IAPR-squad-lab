{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "upset-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_classification import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-mechanism",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "elementary-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_suits = os.path.join('data', 'classification_data', 'all_suits.pickle')\n",
    "segmented = pd.read_pickle(filepath_suits)\n",
    "values = segmented.values\n",
    "imgs = [v[1] for v in values]\n",
    "ranks = [v[0][0] for v in values]\n",
    "suits = [v[0][1] for v in values]\n",
    "\n",
    "df_suits = pd.DataFrame({\"rank\": ranks, \"suit\": suits, \"image\": imgs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "modified-mozambique",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>suit</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q</td>\n",
       "      <td>S</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q</td>\n",
       "      <td>S</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>H</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.014767156862745413, 0.10263...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>H</td>\n",
       "      <td>[[0.0, 0.0018457382953180593, 0.08874549819927...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J</td>\n",
       "      <td>H</td>\n",
       "      <td>[[0.0, 0.0, 0.0011379551820727707, 0.041544117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>[[0.0, 0.0, 0.001395558223289321, 0.0990896358...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0018907563025208232, 0.0672...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>6</td>\n",
       "      <td>H</td>\n",
       "      <td>[[0.0, 0.0, 0.030687274909964084, 0.2806897759...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>6</td>\n",
       "      <td>H</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.020955882352943024, 0.23497...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>728 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank suit                                              image\n",
       "0      Q    S  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "1      Q    S  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "2      8    H  [[0.0, 0.0, 0.0, 0.014767156862745413, 0.10263...\n",
       "3      8    H  [[0.0, 0.0018457382953180593, 0.08874549819927...\n",
       "4      J    H  [[0.0, 0.0, 0.0011379551820727707, 0.041544117...\n",
       "..   ...  ...                                                ...\n",
       "723    5    C  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "724    2    H  [[0.0, 0.0, 0.001395558223289321, 0.0990896358...\n",
       "725    2    H  [[0.0, 0.0, 0.0, 0.0018907563025208232, 0.0672...\n",
       "726    6    H  [[0.0, 0.0, 0.030687274909964084, 0.2806897759...\n",
       "727    6    H  [[0.0, 0.0, 0.0, 0.020955882352943024, 0.23497...\n",
       "\n",
       "[728 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_suits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-craps",
   "metadata": {},
   "source": [
    "## Augment dataset of suits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "associate-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.RandomAffine(degrees=25, scale=(0.7, 1), shear=25),\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "labels_figures = {'C': 0, 'D': 1, 'H': 2, 'S': 3}\n",
    "\n",
    "train_augmented_suits, train_augmented_suits_labels, val_augmented_suits, val_augmented_suits_labels, \\\n",
    "            test_suits, test_suits_labels = \\\n",
    "            get_train_val_test_suits(df_suits, labels_figures, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-domain",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "numerous-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of our DataLoader\n",
    "params = {'batch_size': 128,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Creation of a train/test dataset & dataloader \n",
    "ds_train = MNISTDataset(train_augmented_suits, train_augmented_suits_labels, transform=transforms.ToTensor())\n",
    "dl_train = data.DataLoader(ds_train, **params)\n",
    "\n",
    "ds_val = MNISTDataset(val_augmented_suits, val_augmented_suits_labels, transform=transforms.ToTensor())\n",
    "dl_val = data.DataLoader(ds_val, **params)\n",
    "\n",
    "ds_test = MNISTDataset(test_suits, test_suits_labels, transform=transforms.ToTensor())\n",
    "dl_test = data.DataLoader(ds_test, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-wednesday",
   "metadata": {},
   "source": [
    "# Training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-digit",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aware-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(nb_classes=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-literature",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sensitive-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "learning_rate = 1e-3\n",
    "opt = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "guided-mechanism",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "It 30/30:\tLoss train: 0.32101, Accuracy train: 89.41%\n",
      "Test Error:\n",
      "\tAvg loss: 0.00168, Accuracy: 94.32%\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "It 30/30:\tLoss train: 0.04839, Accuracy train: 98.82%\n",
      "Test Error:\n",
      "\tAvg loss: 0.00026, Accuracy: 100.00%\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "It 30/30:\tLoss train: 0.02327, Accuracy train: 100.00%\n",
      "Test Error:\n",
      "\tAvg loss: 0.00016, Accuracy: 100.00%\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "It 30/30:\tLoss train: 0.08096, Accuracy train: 97.65%%\n",
      "Test Error:\n",
      "\tAvg loss: 0.00012, Accuracy: 100.00%\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "It 30/30:\tLoss train: 0.01632, Accuracy train: 100.00%\n",
      "Test Error:\n",
      "\tAvg loss: 0.00009, Accuracy: 100.00%\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "It 30/30:\tLoss train: 0.07442, Accuracy train: 98.82%%\n",
      "Test Error:\n",
      "\tAvg loss: 0.00011, Accuracy: 100.00%\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "It 30/30:\tLoss train: 0.00631, Accuracy train: 100.00%\n",
      "Test Error:\n",
      "\tAvg loss: 0.00028, Accuracy: 99.46%\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "It 30/30:\tLoss train: 0.01974, Accuracy train: 98.82%%\n",
      "Test Error:\n",
      "\tAvg loss: 0.00008, Accuracy: 100.00%\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "It 30/30:\tLoss train: 0.01606, Accuracy train: 100.00%\n",
      "Test Error:\n",
      "\tAvg loss: 0.00008, Accuracy: 100.00%\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "It 30/30:\tLoss train: 0.03709, Accuracy train: 98.82%%\n",
      "Test Error:\n",
      "\tAvg loss: 0.00013, Accuracy: 100.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "# Train & test our model until convergence\n",
    "for e in range(epochs):\n",
    "    print(f\"Epoch {e+1}\\n-------------------------------\")\n",
    "    train_loop(dl_train, model, criterion, opt)\n",
    "    test_loop(dl_val, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "foreign-array",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:\n",
      "\tAvg loss: 0.00116, Accuracy: 98.64%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loop(dl_test, model, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-fifteen",
   "metadata": {},
   "source": [
    "## Save model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sixth-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = os.path.join('data', 'models')\n",
    "\n",
    "if not os.path.isdir(models_dir):\n",
    "    os.mkdir(models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "removable-conducting",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(models_dir, \"model_suits.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "muslim-insurance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(test_suits, 4, Net, \"data/models/model_suits.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-chemical",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:iapr] *",
   "language": "python",
   "name": "conda-env-iapr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
