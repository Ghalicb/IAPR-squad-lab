{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sunrise-belfast",
   "metadata": {},
   "source": [
    "# [IAPR][iapr]: Project\n",
    "\n",
    "\n",
    "**Group ID:** 32\n",
    "\n",
    "**Author 1 (sciper):** Ghali CHRAIBI (262251)  \n",
    "**Author 2 (sciper):** Yann Yasser HADDAD (272292)   \n",
    "**Author 3 (sciper):** Julien BERGER (xxxxx)   \n",
    "\n",
    "**Release date:** 07.05.2021  \n",
    "**Due date:** 03.06.2021 (23h59)\n",
    "\n",
    "\n",
    "## Important notes\n",
    "\n",
    "The lab assignments are designed to teach practical implementation of the topics presented during class as well as preparation for the final project, which is a practical project which ties together the topics of the course. \n",
    "\n",
    "As such, in the lab assignments/final project, unless otherwise specified, you may, if you choose, use external functions from image processing/ML libraries like opencv and sklearn as long as there is sufficient explanation in the lab report. For example, you do not need to implement your own edge detector, etc.\n",
    "\n",
    "**! Before handling back the notebook !** rerun the notebook from scratch `Kernel` > `Restart & Run All`\n",
    "\n",
    "\n",
    "[iapr]: https://github.com/LTS5/iapr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-relations",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-declaration",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "north-violin",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4dde705f1c46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objects\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import skimage.io\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import print_results, evaluate_game\n",
    "from skimage.color import label2rgb, gray2rgb, rgb2gray, rgb2hsv\n",
    "from skimage.transform import resize, rotate, rescale\n",
    "from skimage.util import img_as_ubyte, crop\n",
    "from skimage.filters import (laplace, prewitt, sobel, roberts, median,\n",
    "gaussian, threshold_otsu, threshold_multiotsu,  difference_of_gaussians,\n",
    "threshold_isodata, threshold_mean, threshold_yen, threshold_sauvola,\n",
    "threshold_niblack, threshold_triangle, threshold_li, threshold_local)\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label, regionprops, regionprops_table, find_contours\n",
    "from skimage.morphology import (disk, square, closing, binary_opening,\n",
    "binary_closing, opening, binary_dilation, binary_erosion, remove_small_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "meaning-lemon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "legendary-covering",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2f55eac63949>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Torch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Torch\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-phenomenon",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Introduction\n",
    "\n",
    "An anonymous researcher that we will name Lann Yecun is convinced that the MNIST dataset still has great potential. He decides to create a playing card game based on MNIST digits and different figures. The game uses a standard 52 card deck which is composed of four French suits/colours: clubs (&#9827;), diamonds (&#9830;), hearts (&#9829;) and spades (&#9824;). Each suit includes 10 digit cards (from 0 to 9) and 3 figures (Jack-J, Queen-Q, and King-K). Here is an example of the 13 spade cards with their name.\n",
    "\n",
    "\n",
    "<img src=\"data/media/example_cards.png\">\n",
    "\n",
    "\n",
    "We can find the same arrangement of cards for the clubs, diamonds, and hearts. \n",
    "\n",
    "\n",
    "## 1. Rules\n",
    "\n",
    "\n",
    "### 1.1 Standard\n",
    "\n",
    "The rules are based on the simple battle card game. The goal of the game is to win as many points as possible. Each turn, the 4 players play a card in front of them. As displayed in the example below. The rules are the following:\n",
    "\n",
    "- The cards are ranked in the following order : **0 < 1 < 2 < 3 < 4 < 5 < 6 < 7 < 8 < 9 < J < Q < K**.\n",
    "- The player with the highest-ranked card wins the round and obtains **1 point**. \n",
    "- If the highest-ranked card is the same for multiple players we call it a draw and all winners get **1 points**. \n",
    "- In this configuration, we **do not** take into account the suits. The game only rely on the card ranks. \n",
    "- The game lasts 13 rounds. After the last round, the winner is the player that has the largest number of points. \n",
    "- In the example below Player 1 wins the round with his Queen ( 0 < 8 < J < **Q**).\n",
    "\n",
    "If two or more players have the same number of points they share the victory.\n",
    "\n",
    "### 1.2 Advanced\n",
    "\n",
    "The advanced rules take into account the suits. \n",
    "\n",
    "- At the beginning of **each round** a random player is designated as the **dealer**. The dealer places a green token with the letter *D* next to him (player 1 in the example below).\n",
    "- Only the cards that belong to the same suit as the one of the dealer are considered valid. In the example below, only Player 4 is competing with Player 1 as spade was selected by the dealer (e.i., Player 1). Player 2 and 3 are out for this round. Player 1 wins the round and **1 point** with the Queen ( 0&#9824; < **Q&#9824;**).\n",
    "- There cannot be any draw between the players as they are not any card duplicates.\n",
    "- We use the same system as the standard method to count the points.\n",
    "\n",
    "\n",
    "<img src=\"data/media/example_round.jpg\">\n",
    "\n",
    "\n",
    "### 1.3 Notes\n",
    "\n",
    "- The orientation of the card is linked to the position of the player around the table. For instance, to read the card of the 3rd player you will have to rotate it by 180Â°.\n",
    "- The **digits** always **face** the players around the table. The figures can have random orientations.\n",
    "- Player 1 **always** seats south of the table. The players are **always** ordered counter-clockwise as in the example. \n",
    "- The dealers can change between the rounds and games.\n",
    "- Some cards **might** apear multiple times per game.\n",
    "- Pictures are always taken from rougthly the same altitude.\n",
    "- The digits from the training set **would not** be the same as the one of the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-shelter",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data\n",
    "\n",
    "You will be given the images of 7 games that were played ([download link](https://drive.google.com/drive/folders/1fEy27wnJsUJPRsEEomzoAtP56s-7HFtk?usp=sharing)). The data are composed of:\n",
    "   - 7 folder named after the games (game1 to game7).\n",
    "   - Each game includes 13 ordered images (1st to 13th round).\n",
    "   - Each game includes a csv file with the ground truth of the game. The first row list the players (P1 to P4) as well as the dealer (D). The following rows represent the rounds (1 to 13). We represent the card played with 2 character as $AB$ where $A \\in [0-9, J, Q, K]$ is the rank of the card and $B \\in [C, D, H, S]$ is the suit. For example, QS means \"(Q)ueen of (S)pade\" and 0D means \"(0) of (D)iamond\". The dealer is represented by the ID of the player (e.g. P1 -> 1).\n",
    "   \n",
    "You are free to use external datasets such as the original MNIST train set that you used in lab 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-geography",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = 'data/train_games'\n",
    "train_game_count = 7\n",
    "game_round_count = 13\n",
    "\n",
    "dict_data = {}\n",
    "\n",
    "for i in range(1, train_game_count+1):\n",
    "    # For each game, store the path of the csv and the image of each round\n",
    "    dict_data[f'game{i}'] = {}\n",
    "    dict_data[f'game{i}']['url'] = train_data + f'/game{i}'\n",
    "    dict_data[f'game{i}']['csv'] = train_data + f'/game{i}.csv'\n",
    "    \n",
    "    for j in range(1, game_round_count+1):\n",
    "        dict_data[f'game{i}'][f'round{j}'] = skimage.io.imread(train_data + f'/game{i}/{j}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "ax.imshow(dict_data['game3']['round7'])\n",
    "ax.set_title('Game1 Round1')\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-marathon",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Your Tasks\n",
    "\n",
    "Your task is to ready yourself for the final evaluation. The day of the exam we will give you a new folder with a new game. ! The digits on the cards **differ** from the one of the traning set. When given a new data folder with 13 images your should be able to:\n",
    "\n",
    "**Task 0**\n",
    "   - Plot an overlay for each round image that shows your detections and classification. You can for example plot bounding boxes around the cards/dealer token and add a text overlay with the name of the classes.\n",
    "\n",
    "**Task 1**\n",
    "   - (a) Predict the **rank** of the card played by each player at each round (Standard rules).\n",
    "   - (b) Predict the **number of points** of each player according to **Standard** rules\n",
    " \n",
    "**Task 2**\n",
    "   - (a) Detect which player is the selected **dealer** for each round.\n",
    "   - (b) Predict the **rank** and the **suit** of the card played by each player at each round (Advanced rules).\n",
    "   - (c) Predict the **number of points** of each player according to **Advanced** rules\n",
    "\n",
    "---\n",
    "\n",
    "**Before the exam (until 03.06.21 at 23h59)**\n",
    "   - Create a zipped folder named **group_xx.zip** that you upload on moodle (xx being your group number).\n",
    "   - Include a **runnable** code (Jupyter Notebook and external files) and your presentation in the zip folder.\n",
    "   \n",
    "**The day of the exam (04.06.21)**\n",
    "   - You will be given a **new folder** with 13 images (rounds) and but **no ground truth** (csv file).\n",
    "   - We will ask you to run your pipeline in **realtime** and to send us your prediction of task 1 and 2 that you obtain with the function **print_results**. \n",
    "   - On our side we will compute the perfomance of your classification algorithm. \n",
    "   - To evaluate your method we will use the **evaluate_game** function presented below. To understand how the provided functions work please read the documentation of the functions in **utils.py**.\n",
    "   - **Please make sure your function returns the proper data format to avoid points penalty the day of the exam**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-balloon",
   "metadata": {},
   "source": [
    "### Segmentation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: coloured image of the round\n",
    "#Output: DataFrame containing all segmented objects (cards + dealer + random objects)\n",
    "#with geometrical properties\n",
    "\n",
    "def find_potential_objects_in_original_round_image(coloured_image):\n",
    "    hsv_img = rgb2hsv(coloured_image) \n",
    "    hsv_img = img_as_ubyte(hsv_img) # Convert 0-1 to 0-255 \n",
    "    \n",
    "    thres_brightness = threshold_multiotsu(hsv_img[:,:,2]).max() # threshold for the \"value\" channel\n",
    "    \n",
    "    # HSV image is filtered on the 3 channels:\n",
    "    # H: [145-200] white colour , S: [0-255] , V: [threshold-255] high values\n",
    "    filtered_im = cv2.inRange(hsv_img, np.array([145,0,thres_brightness]), np.array([200,255,255])) # Binary filtered image\n",
    "    \n",
    "    labeled_im = label(filtered_im, background=None, connectivity=filtered_im.ndim) # Find objects using region growing and labeling\n",
    "    labeled_im = remove_small_objects(labeled_im, min_size=30000) # Remove objects smaller than the dealer and the cards\n",
    "    labeled_im = median(labeled_im, square(15)) # Remove noise\n",
    "    \n",
    "    # Dictionnary that stores information for each segmented objects \n",
    "    props_objs = regionprops_table(labeled_im, properties=(\n",
    "                                                  \"label\",\n",
    "                                                  \"area\",\n",
    "                                                  \"filled_area\",\n",
    "                                                  \"major_axis_length\",\n",
    "                                                  \"minor_axis_length\",\n",
    "                                                  'centroid',\n",
    "                                                  \"slice\",\n",
    "                                                  \"image\"\n",
    "                                                   ))\n",
    "    df_objs = pd.DataFrame(props_objs)\n",
    "    df_objs[\"labeled_im\"] = 0 # random value\n",
    "    df_objs[\"labeled_im\"] = df_objs[\"labeled_im\"].apply(lambda x: labeled_im)\n",
    "    \n",
    "    \n",
    "    return df_objs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-angola",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: DataFrame containing all the potential objects \n",
    "#Output: DataFrame with 4 objects corresponding to the 4 cards (unordered)\n",
    "\n",
    "def select_cards_from_potential_objects(df_objs): \n",
    "    \n",
    "    # Features differentiating cards from the rest of the objects\n",
    "    # These are reference values obtained by exploring the dataset\n",
    "    C_REF_MAJOR_AXIS_MEAN = 838\n",
    "    C_REF_MAJOR_AXIS_STD = 16\n",
    "    C_REF_MINOR_AXIS_MEAN = 542\n",
    "    C_REF_MINOR_AXIS_STD = 23\n",
    "    \n",
    "    cards_feature1_series = (df_objs[\"major_axis_length\"]-C_REF_MAJOR_AXIS_MEAN)/C_REF_MAJOR_AXIS_STD # Normalized feature 1 \n",
    "    cards_feature2_series = (df_objs[\"minor_axis_length\"]-C_REF_MINOR_AXIS_MEAN)/C_REF_MINOR_AXIS_STD # Normalized feature 2\n",
    "    \n",
    "    # Euclidian distance corresponding to the similarity between an object and the reference card.\n",
    "    # The smaller the distance, the greater the similarity. Here the 4 most similar objects are kept.\n",
    "    cards_similarity_distances_series = (cards_feature1_series**2+cards_feature2_series**2)**0.5 # Euclidian distance\n",
    "    df_objs[\"card_similarity_measure\"] = cards_similarity_distances_series\n",
    "    \n",
    "    return df_objs.nsmallest(4, \"card_similarity_measure\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: DataFrame containing all the potential objects \n",
    "#Output: Series with 1 object corresponding to the dealer\n",
    "\n",
    "def select_dealer_from_potential_objects(df_objs): \n",
    "    \n",
    "    # Features differentiating the dealer from the rest of the objects\n",
    "    # These are reference values obtained by exploring the dataset\n",
    "    D_REF_AREA_MEAN = 45061\n",
    "    D_REF_AREA_STD = 1202\n",
    "    D_REF_FILLED_AREA_MEAN = 65325\n",
    "    D_REF_FILLED_AREA_STD = 1134\n",
    "\n",
    "    dealer_feature1_series = (df_objs[\"area\"]-D_REF_AREA_MEAN)/D_REF_AREA_STD # Normalized feature 1 \n",
    "    dealer_feature2_series = (df_objs[\"filled_area\"]-D_REF_FILLED_AREA_MEAN)/D_REF_FILLED_AREA_STD # Normalized feature 2\n",
    "    \n",
    "    # Euclidian distance corresponding to the similarity between an object and the reference dealer.\n",
    "    # The smaller the distance, the greater the similarity. Here the most similar object is kept.\n",
    "    dealer_similarity_distances_series = (dealer_feature1_series**2+dealer_feature2_series**2)**0.5 # Euclidian distance\n",
    "    df_objs[\"dealer_similarity_measure\"] = dealer_similarity_distances_series\n",
    "    \n",
    "    return df_objs.nsmallest(1, \"dealer_similarity_measure\").iloc[0] #Return a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: Original image of the round; DataFrame containing the 4 card objects\n",
    "#Output: Ordered DataFrame (index 0 = player 1; index 1 = player 2; index 2 = player 3; index 3 = player 4)\n",
    "#that contains the extracted cards (colour and binary version). Extracted cards are also rotated depending on\n",
    "#the player position\n",
    "\n",
    "def extract_cards_from_original_round_image(coloured_image, cards_only_df):\n",
    "\n",
    "    ordered_cards_only_df = pd.DataFrame()\n",
    "    \n",
    "    # Players are found using the centroid of the card object. Centroid = (x0, y0)\n",
    "    player1_series = cards_only_df.loc[cards_only_df[\"centroid-0\"].idxmax()] # Player 1 has the highest x0\n",
    "    \n",
    "    # The \"slice\" property is used to extract the card from the original image\n",
    "    player1_series[\"image_coloured\"] = coloured_image[player1_series[\"slice\"]] \n",
    "   \n",
    "    player2_series = cards_only_df.loc[cards_only_df[\"centroid-1\"].idxmax()] # Player 2 has the highest y0\n",
    "    \n",
    "    # The \"image\" property is used to extract the card from the original image in binary version\n",
    "    player2_series[\"image\"] = rotate(player2_series[\"image\"], -90, resize=True) # Rotation of the extracted binary card\n",
    "    player2_series[\"image_coloured\"] = rotate(coloured_image[player2_series[\"slice\"]], -90, resize=True)\n",
    "\n",
    "    player3_series = cards_only_df.loc[cards_only_df[\"centroid-0\"].idxmin()] # Player 3 has the lowest x0\n",
    "    player3_series[\"image\"] = rotate(player3_series[\"image\"], 180, resize=True)\n",
    "    player3_series[\"image_coloured\"] = rotate(coloured_image[player3_series[\"slice\"]], 180, resize=True)\n",
    "\n",
    "    player4_series = cards_only_df.loc[cards_only_df[\"centroid-1\"].idxmin()] # Player 4 has the lowest y0\n",
    "    player4_series[\"image\"] = rotate(player4_series[\"image\"], 90, resize=True)\n",
    "    player4_series[\"image_coloured\"] = rotate(coloured_image[player4_series[\"slice\"]], 90, resize=True)\n",
    "\n",
    "\n",
    "    ordered_cards_only_df = (ordered_cards_only_df.append(player1_series, ignore_index=True)\n",
    "                             .append(player2_series, ignore_index=True)\n",
    "                             .append(player3_series, ignore_index=True)\n",
    "                             .append(player4_series, ignore_index=True))\n",
    "    \n",
    "    ordered_cards_only_df[\"player\"] = [1,2,3,4]\n",
    "    \n",
    "    return ordered_cards_only_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: DataFrame containg the extracted cards in order (index 0 = player 1; index 1 = player 2; index 2 = player 3; index 3 = player 4)\n",
    "# and the dealer series \n",
    "#Output: Same DataFrame with a new column called \"dealer\" (with True and False values)\n",
    "def Add_dealer_status_to_extracted_cards(ordered_cards_only_df, dealer_series):\n",
    "    \n",
    "    dealer_centr0 = dealer_series[\"centroid-0\"]\n",
    "    dealer_centr1 = dealer_series[\"centroid-1\"]\n",
    "   \n",
    "    # To find the dealer, the euclidian distance between the centroids of the cards and the dealer is computed \n",
    "    ordered_cards_only_df[\"dealer\"] = [False,False,False,False]\n",
    "    distances_to_dealer_series = ((ordered_cards_only_df[\"centroid-0\"]-dealer_centr0)**2 + (ordered_cards_only_df[\"centroid-1\"]-dealer_centr1)**2)**0.5 # Euclidian distance\n",
    "    ordered_cards_only_df.loc[distances_to_dealer_series.idxmin(),\"dealer\"] = True\n",
    "    \n",
    "    return ordered_cards_only_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-episode",
   "metadata": {},
   "source": [
    "### Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: coloured image of the round\n",
    "#Output: Series containing a summary of the results (an extracted card for each player + attribution of the dealer) \n",
    "def plot_overlay_for_round_image(coloured_image):\n",
    "    \n",
    "    df_objs = find_potential_objects_in_original_round_image(coloured_image)\n",
    "    \n",
    "    cards_only_df = select_cards_from_potential_objects(df_objs)\n",
    "    dealer_series = select_dealer_from_potential_objects(df_objs)\n",
    "    \n",
    "    ordered_cards_only_df = extract_cards_from_original_round_image(coloured_image, cards_only_df)\n",
    "    ordered_cards_only_df = Add_dealer_status_to_extracted_cards(ordered_cards_only_df, dealer_series)\n",
    "    \n",
    "    \n",
    "    fig = px.imshow(rgb2gray(coloured_image), binary_string=True)\n",
    "    fig.update_traces(hoverinfo='skip') # hover is only for label info\n",
    "    properties = ['player', 'dealer']\n",
    "\n",
    "    # For each label, add a filled scatter trace for its contour,\n",
    "    # and display the properties of the label in the hover of this trace.\n",
    "    result_series = pd.Series() # store information of the round. This is the output of the function\n",
    "    \n",
    "    for index in range(4):\n",
    "        result_series[f\"P{index+1}_extracted_card\"] = (ordered_cards_only_df.iloc[index][\"image_coloured\"], ordered_cards_only_df.iloc[index][\"image\"])\n",
    "        \n",
    "        label_ = ordered_cards_only_df.iloc[index][\"label\"]\n",
    "        contour = find_contours(ordered_cards_only_df.iloc[index][\"labeled_im\"] == label_, 0.5)[0]\n",
    "        y, x = contour.T\n",
    "        hoverinfo = ''\n",
    "        for prop_name in properties:\n",
    "            hoverinfo += f'<b>{prop_name}: {ordered_cards_only_df.iloc[index][prop_name]}</b><br>'\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=x, y=y, #name = label_\n",
    "            mode='lines', fill='toself', showlegend=False,\n",
    "            hovertemplate=hoverinfo, hoveron='points+fills'))\n",
    "    \n",
    "    result_series[\"dealer\"] = int(ordered_cards_only_df[ordered_cards_only_df[\"dealer\"]][\"player\"][0]) #\n",
    "    \n",
    "    label_dealer = dealer_series[\"label\"]\n",
    "    contour_dealer = find_contours(dealer_series[\"labeled_im\"] == label_dealer, 0.5)[0]\n",
    "    y_d, x_d = contour_dealer.T\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_d, y=y_d, name = \"dealer\",\n",
    "        mode='lines', fill='toself', showlegend=False,\n",
    "        hovertemplate=\" \", hoveron='points+fills'))\n",
    "\n",
    "    fig.show()\n",
    "    return result_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: dict_data, game_number\n",
    "#Output: DataFrame containing a summary of the results for each round (an extracted card for each player + attribution of the dealer) \n",
    "def plot_overlay_for_all_round_images(dict_data, game_number=1):\n",
    "    \n",
    "    results_game = pd.DataFrame()\n",
    "    for i in range(13):\n",
    "        coloured_image = dict_data[f\"game{game_number}\"][f\"round{i+1}\"]\n",
    "        print(f\"The segmentation of cards and dealer for round {i+1} is:\")\n",
    "        results_round = plot_overlay_for_round_image(coloured_image)\n",
    "        results_game = results_game.append(results_round, ignore_index=True)\n",
    "    \n",
    "    return results_game\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: coloured image of the round\n",
    "#Output: no output. Just the image in HSV \n",
    "def plot_round_image_in_HSV(coloured_image):\n",
    "        print(\"HSV channels of the image:\")\n",
    "        hsv_img = rgb2hsv(coloured_image) \n",
    "        hsv_img = img_as_ubyte(hsv_img) # Convert 0-1 to 0-255 \n",
    "        fig = px.imshow(hsv_img, binary_string=True)\n",
    "        fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-pharmacology",
   "metadata": {},
   "source": [
    "### Functions to exctract numbers or suits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: extracted Coloured card and the exact same card in binary format (obtained using the [\"image\"] property)\n",
    "#Output: cropped gray-scaled image of the numberin the mnist format\n",
    "def create_mnist_number_from_extracted_coloured_cards(coloured_card, binary_card):\n",
    "    \n",
    "    cropped_binary_card = crop(binary_card, ((binary_card.shape[0]*0.15, binary_card.shape[0]*0.15), (binary_card.shape[1]*0.15, binary_card.shape[1]*0.15)))\n",
    "    cropped_coloured_card = crop(coloured_card, ((coloured_card.shape[0]*0.15, coloured_card.shape[0]*0.15), (coloured_card.shape[1]*0.15, coloured_card.shape[1]*0.15), (0, 0)))\n",
    "\n",
    "    # Take the negative of the segmented binary card (numbers become objects instead of background)\n",
    "    filt1 = (cropped_binary_card == False)\n",
    "    filt2 = (cropped_binary_card == True)\n",
    "    cropped_binary_card[filt1] = True\n",
    "    cropped_binary_card[filt2] = False   \n",
    "    cropped_binary_card = binary_dilation(cropped_binary_card, square(45)) # Closes the number having holes i.e some 5 and 2\n",
    "    labeled_im = remove_small_objects(label(cropped_binary_card), 5000)\n",
    "    \n",
    "    props_objs = regionprops_table(labeled_im, properties=(\n",
    "                                                  \"label\",\n",
    "                                                  \"area\",\n",
    "                                                  'centroid',\"slice\"))\n",
    "    df_objs = pd.DataFrame(props_objs)\n",
    "    coloured_cropped_number = cropped_coloured_card[df_objs.loc[df_objs[\"area\"].idxmax()][\"slice\"]] # extract the number (biggest object)\n",
    "    \n",
    "    \n",
    "    cropped_number_gray = rgb2gray(coloured_cropped_number)\n",
    "    thresh = threshold_otsu(cropped_number_gray)\n",
    "    return resize(img_as_ubyte(cropped_number_gray < thresh), (28,28))\n",
    " \n",
    "#This function can be deleted...\n",
    "#Input: extracted Coloured card in binary format (obtained using the [\"image\"] property)\n",
    "#Output: cropped gray-scaled image of the number in the mnist format\n",
    "def create_mnist_number_from_extracted_binary_cards(binary_card):\n",
    "    \n",
    "    cropped_binary_card = crop(binary_card, ((binary_card.shape[0]*0.15, binary_card.shape[0]*0.15), (binary_card.shape[1]*0.15, binary_card.shape[1]*0.15)))\n",
    "\n",
    "    # Take the negative of the segmented binary card (numbers become objects instead of background)\n",
    "    #filt1 = (cropped_binary_card == False)\n",
    "    #filt2 = (cropped_binary_card == True)\n",
    "    #cropped_binary_card[filt1] = True\n",
    "    #cropped_binary_card[filt2] = False   \n",
    "    cropped_binary_card_ = binary_dilation(cropped_binary_card, square(45)) # Closes the number having holes i.e some 5 and 2\n",
    "    labeled_im = remove_small_objects(label(cropped_binary_card_), 5000)\n",
    "    \n",
    "    props_objs = regionprops_table(labeled_im, properties=(\n",
    "                                                  \"label\",\n",
    "                                                  \"area\",\n",
    "                                                  'centroid',\"slice\"))\n",
    "    df_objs = pd.DataFrame(props_objs)\n",
    "    binary_cropped_number = cropped_binary_card[df_objs.loc[df_objs[\"area\"].idxmax()][\"slice\"]] #extract the number (biggest object)\n",
    "    \n",
    "    return resize(binary_cropped_number, (28,28))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: extracted Coloured card \n",
    "#Output: cropped gray-scaled image of the suit in the mnist format\n",
    "def create_mnist_suit_from_extracted_coloured_cards(coloured_card, upper_left=True):\n",
    "    if (upper_left):\n",
    "        cropped_coloured_card = crop(coloured_card, ((0, coloured_card.shape[0]*0.6), (0, coloured_card.shape[1]*0.5), (0, 0)))\n",
    "    else:\n",
    "        cropped_coloured_card = crop(coloured_card, ((coloured_card.shape[0]*0.6, 0), (coloured_card.shape[1]*0.5, 0), (0, 0)))\n",
    "\n",
    "    cropped_coloured_card_gray = rgb2gray(cropped_coloured_card)\n",
    "    thresh = threshold_otsu(cropped_coloured_card_gray)\n",
    "    cropped_coloured_card_gray_binary = img_as_ubyte(cropped_coloured_card_gray < thresh)\n",
    "    labeled_im = label(cropped_coloured_card_gray_binary)\n",
    "    labeled_im = clear_border(labeled_im)\n",
    "    #labeled_im = remove_small_objects(labeled_im, 1000)\n",
    "    #labeled_im = median(labeled_im, rect(5))\n",
    "\n",
    "    \n",
    "    props_objs = regionprops_table(labeled_im, properties=(\n",
    "                                                  \"label\",\n",
    "                                                  \"area\",\n",
    "                                                  'centroid',\"slice\"))\n",
    "    df_objs = pd.DataFrame(props_objs)\n",
    "    extracted_suit_coloured = cropped_coloured_card[df_objs.loc[df_objs[\"area\"].idxmax()][\"slice\"]]\n",
    "    \n",
    "    extracted_suit_gray = rgb2gray(extracted_suit_coloured)\n",
    "    thresh = threshold_otsu(extracted_suit_gray)\n",
    "    return resize(img_as_ubyte(extracted_suit_gray < thresh), (28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-telling",
   "metadata": {},
   "source": [
    "### Functions used to create training sets for number and suit recognition\n",
    "#### Cells are in MARKDOWN because there is no need to run them again. It takes time (30min) and will overwrite already existing files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-ethernet",
   "metadata": {},
   "source": [
    "#Input: dict_data\n",
    "#Output: Series with each element being a tuple (\"3H\", mnist_image_method1, mnist_image_method2)\n",
    "def create_training_set_for_numbers(dict_data):\n",
    "    \n",
    "    final_series = pd.Series()\n",
    "    for game_number in range(7):\n",
    "        player1_cards_coloured = []\n",
    "        player2_cards_coloured = []\n",
    "        player3_cards_coloured = []\n",
    "        player4_cards_coloured = []\n",
    "\n",
    "        player1_cards_binary = []\n",
    "        player2_cards_binary = []\n",
    "        player3_cards_binary = []\n",
    "        player4_cards_binary = []\n",
    "\n",
    "        for i in range(13):\n",
    "            coloured_image = dict_data[f'game{game_number+1}'][f'round{i+1}']\n",
    "\n",
    "            df_objs = find_potential_objects_in_original_round_image(coloured_image)\n",
    "            cards_only_df = select_cards_from_potential_objects(df_objs)      \n",
    "            cards_ordered_df = extract_cards_from_original_round_image(coloured_image, cards_only_df)\n",
    "\n",
    "\n",
    "            player1_cards_coloured.append(cards_ordered_df.loc[0][\"image_coloured\"])\n",
    "            player2_cards_coloured.append(cards_ordered_df.loc[1][\"image_coloured\"])\n",
    "            player3_cards_coloured.append(cards_ordered_df.loc[2][\"image_coloured\"])\n",
    "            player4_cards_coloured.append(cards_ordered_df.loc[3][\"image_coloured\"])\n",
    "\n",
    "            player1_cards_binary.append(cards_ordered_df.loc[0][\"image\"])\n",
    "            player2_cards_binary.append(cards_ordered_df.loc[1][\"image\"])\n",
    "            player3_cards_binary.append(cards_ordered_df.loc[2][\"image\"])\n",
    "            player4_cards_binary.append(cards_ordered_df.loc[3][\"image\"])\n",
    "\n",
    "\n",
    "        player_cards_df = pd.DataFrame()\n",
    "\n",
    "        player_cards_df[\"P1_coloured\"] = pd.Series(player1_cards_coloured)\n",
    "        player_cards_df[\"P2_coloured\"] = pd.Series(player2_cards_coloured)\n",
    "        player_cards_df[\"P3_coloured\"] = pd.Series(player3_cards_coloured)\n",
    "        player_cards_df[\"P4_coloured\"] = pd.Series(player4_cards_coloured)\n",
    "\n",
    "        player_cards_df[\"P1_binary\"] = pd.Series(player1_cards_binary)\n",
    "        player_cards_df[\"P2_binary\"] = pd.Series(player2_cards_binary)\n",
    "        player_cards_df[\"P3_binary\"] = pd.Series(player3_cards_binary)\n",
    "        player_cards_df[\"P4_binary\"] = pd.Series(player4_cards_binary)\n",
    "\n",
    "        training_list = []\n",
    "        true_df = pd.read_csv(f\"data/train_games/game{game_number+1}/game{game_number+1}.csv\")\n",
    "        for i in range (13):\n",
    "            training_list.append((true_df.loc[i,\"P1\"],\n",
    "                                  create_mnist_number_from_extracted_coloured_cards(player_cards_df.loc[i, \"P1_coloured\"],player_cards_df.loc[i, \"P1_binary\"]),\n",
    "                                  create_mnist_number_from_extracted_binary_cards(player_cards_df.loc[i, \"P1_binary\"])))\n",
    "\n",
    "            training_list.append((true_df.loc[i,\"P2\"],\n",
    "                                  create_mnist_number_from_extracted_coloured_cards(player_cards_df.loc[i, \"P2_coloured\"],player_cards_df.loc[i, \"P2_binary\"]),\n",
    "                                  create_mnist_number_from_extracted_binary_cards(player_cards_df.loc[i, \"P2_binary\"])))\n",
    "\n",
    "            training_list.append((true_df.loc[i,\"P3\"],\n",
    "                                  create_mnist_number_from_extracted_coloured_cards(player_cards_df.loc[i, \"P3_coloured\"],player_cards_df.loc[i, \"P3_binary\"]),\n",
    "                                  create_mnist_number_from_extracted_binary_cards(player_cards_df.loc[i, \"P3_binary\"])))\n",
    "\n",
    "            training_list.append((true_df.loc[i,\"P4\"],\n",
    "                                  create_mnist_number_from_extracted_coloured_cards(player_cards_df.loc[i, \"P4_coloured\"],player_cards_df.loc[i, \"P4_binary\"]),\n",
    "                                  create_mnist_number_from_extracted_binary_cards(player_cards_df.loc[i, \"P4_binary\"])))\n",
    "\n",
    "        \n",
    "        training_seriesj = pd.Series(training_list)\n",
    "        final_series=pd.concat([final_series,training_seriesj])\n",
    "        print(f\"game{game_number+1}: registered\")\n",
    "\n",
    "    final_series.reset_index().to_pickle(f'data/classification_data/all_games_classification_series_mnist.pickle')\n",
    "    \n",
    "    \n",
    "\n",
    "    return final_series\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-ceiling",
   "metadata": {},
   "source": [
    "#Input: dict_data\n",
    "#Output: Series with each element being a tuple (\"3H\", image_coloured, binary_image)\n",
    "def create_semi_training_set_for_suits(dict_data):\n",
    "    \n",
    "    final_series = pd.Series()\n",
    "    for game_number in range(7):\n",
    "        player1_cards_coloured = []\n",
    "        player2_cards_coloured = []\n",
    "        player3_cards_coloured = []\n",
    "        player4_cards_coloured = []\n",
    "\n",
    "        player1_cards_binary = []\n",
    "        player2_cards_binary = []\n",
    "        player3_cards_binary = []\n",
    "        player4_cards_binary = []\n",
    "\n",
    "        for i in range(13):\n",
    "            coloured_image = dict_data[f'game{game_number+1}'][f'round{i+1}']\n",
    "\n",
    "            df_objs = find_potential_objects_in_original_round_image(coloured_image)\n",
    "            cards_only_df = select_cards_from_potential_objects(df_objs)      \n",
    "            cards_ordered_df = extract_cards_from_original_round_image(coloured_image, cards_only_df)\n",
    "\n",
    "\n",
    "            player1_cards_coloured.append(cards_ordered_df.loc[0][\"image_coloured\"])\n",
    "            player2_cards_coloured.append(cards_ordered_df.loc[1][\"image_coloured\"])\n",
    "            player3_cards_coloured.append(cards_ordered_df.loc[2][\"image_coloured\"])\n",
    "            player4_cards_coloured.append(cards_ordered_df.loc[3][\"image_coloured\"])\n",
    "\n",
    "            player1_cards_binary.append(cards_ordered_df.loc[0][\"image\"])\n",
    "            player2_cards_binary.append(cards_ordered_df.loc[1][\"image\"])\n",
    "            player3_cards_binary.append(cards_ordered_df.loc[2][\"image\"])\n",
    "            player4_cards_binary.append(cards_ordered_df.loc[3][\"image\"])\n",
    "\n",
    "\n",
    "        player_cards_df = pd.DataFrame()\n",
    "\n",
    "        player_cards_df[\"P1_coloured\"] = pd.Series(player1_cards_coloured)\n",
    "        player_cards_df[\"P2_coloured\"] = pd.Series(player2_cards_coloured)\n",
    "        player_cards_df[\"P3_coloured\"] = pd.Series(player3_cards_coloured)\n",
    "        player_cards_df[\"P4_coloured\"] = pd.Series(player4_cards_coloured)\n",
    "\n",
    "        player_cards_df[\"P1_binary\"] = pd.Series(player1_cards_binary)\n",
    "        player_cards_df[\"P2_binary\"] = pd.Series(player2_cards_binary)\n",
    "        player_cards_df[\"P3_binary\"] = pd.Series(player3_cards_binary)\n",
    "        player_cards_df[\"P4_binary\"] = pd.Series(player4_cards_binary)\n",
    "\n",
    "        training_list = []\n",
    "        true_df = pd.read_csv(f\"data/train_games/game{game_number+1}/game{game_number+1}.csv\")\n",
    "        for i in range (13):\n",
    "            training_list.append((true_df.loc[i,\"P1\"],\n",
    "                                  player_cards_df.loc[i, \"P1_coloured\"],\n",
    "                                  player_cards_df.loc[i, \"P1_binary\"]))\n",
    "\n",
    "            training_list.append((true_df.loc[i,\"P2\"],\n",
    "                                  player_cards_df.loc[i, \"P2_coloured\"],\n",
    "                                  player_cards_df.loc[i, \"P2_binary\"]))\n",
    "\n",
    "            training_list.append((true_df.loc[i,\"P3\"],\n",
    "                                  player_cards_df.loc[i, \"P3_coloured\"],\n",
    "                                  player_cards_df.loc[i, \"P3_binary\"]))\n",
    "\n",
    "            training_list.append((true_df.loc[i,\"P4\"],\n",
    "                                  player_cards_df.loc[i, \"P4_coloured\"],\n",
    "                                  player_cards_df.loc[i, \"P4_binary\"]))\n",
    "        \n",
    "        training_seriesj = pd.Series(training_list)\n",
    "        final_series=pd.concat([final_series, training_seriesj])\n",
    "        print(f\"game{game_number+1}: registered\")\n",
    "\n",
    "    final_series.reset_index().to_pickle(f'data/classification_data/all_games_classification_series_semi_suits.pickle')\n",
    "    \n",
    "    return final_series\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-provincial",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#Input: semi_suits_df\n",
    "#Output: Series with each element being a tuple (\"3H\", suit_in_mnist_format)\n",
    "def create_training_set_for_suits(semi_suits_df):\n",
    "    semi_suits_df  = semi_suits_df.reset_index()\n",
    "    training_list = []\n",
    "    for i in range(364):\n",
    "        coloured_card = semi_suits_df.iloc[i][0][1]\n",
    "        suit_upper_left = create_mnist_suit_from_extracted_coloured_cards(coloured_card, True)\n",
    "        suit_lower_right = create_mnist_suit_from_extracted_coloured_cards(coloured_card, False)\n",
    "        suit_name = semi_suits_df.iloc[i][0][0]\n",
    "        training_list.append((suit_name, suit_upper_left))\n",
    "        training_list.append((suit_name, rotate(suit_lower_right, 180)))\n",
    "\n",
    "    training_series = pd.Series(training_list)\n",
    "    training_series.to_pickle(f'data/classification_data/all_games_classification_series_728_suits.pickle')\n",
    "    return training_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-timer",
   "metadata": {},
   "source": [
    "### Task 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-alexander",
   "metadata": {},
   "source": [
    "### HSV exploration for 2 random round images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_round_image_in_HSV(dict_data['game2']['round1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_round_image_in_HSV(dict_data['game6']['round4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-dutch",
   "metadata": {},
   "source": [
    "To detect the cards and the dealer, we transformed the RGB image into a HSV image. By exploring the images, we discovered that the backgrounds of the cards and the D of the dealer coin had more or less the same HSV values (purple areas):\n",
    "H: between 145 and 200 |\n",
    "S: between 0 and 255 |\n",
    "V: between ~170 and 255.\n",
    "\n",
    "Our segmentation method called find_potential_objects_in_original_round_image() uses these ranges of values to detect the cards and the dealer (+ some noise objects that are removed later)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-cattle",
   "metadata": {},
   "source": [
    "### Segmentation results for 2 random round images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-engagement",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = plot_overlay_for_round_image(dict_data['game1']['round1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = plot_overlay_for_round_image(dict_data['game1']['round2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### PIPELINE FOR EXAM ##########################\n",
    "path_to_image_folder = \"TO BE FILLED\"\n",
    "dict_data_test = {}\n",
    "dict_data_test[\"game1\"] = {}\n",
    "for i in range(13):\n",
    "    dict_data['game1'][f'round{i+1}'] = skimage.io.imread(f\"{path_to_image_folder}/{i+1}.jpg\")\n",
    "\n",
    "\n",
    "def plot_overlay_for_all_round_images(dict_data_test, game_number=1):\n",
    "    \n",
    "    for i in range(13):\n",
    "        coloured_image = dict_data[f\"game{game_number}\"][f\"round{i+1}\"]\n",
    "        print(f\"The segmentation of cards and dealer for round {i+1} is:\")\n",
    "        plot_overlay_for_round_image(coloured_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-liability",
   "metadata": {},
   "source": [
    "### Pipeline: show segmentation for task 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-deadline",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df = plot_overlay_for_all_round_images(dict_data, game_number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-cooling",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_results_df_into_mnist_cards(results_df):\n",
    "    results_df[\"P1_mnist_number\"] = results_df[\"P1_extracted_card\"].apply(lambda card: create_mnist_number_from_extracted_coloured_cards(card[0], card[1]))\n",
    "    results_df[\"P2_mnist_number\"] = results_df[\"P2_extracted_card\"].apply(lambda card: create_mnist_number_from_extracted_coloured_cards(card[0], card[1]))\n",
    "    results_df[\"P3_mnist_number\"] = results_df[\"P3_extracted_card\"].apply(lambda card: create_mnist_number_from_extracted_coloured_cards(card[0], card[1]))\n",
    "    results_df[\"P4_mnist_number\"] = results_df[\"P4_extracted_card\"].apply(lambda card: create_mnist_number_from_extracted_coloured_cards(card[0], card[1]))\n",
    "\n",
    "    results_df[\"P1_mnist_suit\"] = results_df[\"P1_extracted_card\"].apply(lambda card: create_mnist_suit_from_extracted_coloured_cards(card[0], upper_left=True))\n",
    "    results_df[\"P2_mnist_suit\"] = results_df[\"P2_extracted_card\"].apply(lambda card: create_mnist_suit_from_extracted_coloured_cards(card[0], upper_left=True))\n",
    "    results_df[\"P3_mnist_suit\"] = results_df[\"P3_extracted_card\"].apply(lambda card: create_mnist_suit_from_extracted_coloured_cards(card[0], upper_left=True))\n",
    "    results_df[\"P4_mnist_suit\"] = results_df[\"P4_extracted_card\"].apply(lambda card: create_mnist_suit_from_extracted_coloured_cards(card[0], upper_left=True))\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_df  = transform_results_df_into_mnist_cards(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-implement",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEF Function PREDICT_NUMBER_FROM_MNIST\n",
    "# DEF Function PREDICT_SUIT_FROM_MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_number_from_mnist(mnist_image):\n",
    "    return \"4\"\n",
    "\n",
    "def predict_suit_from_mnist(mnist_image):\n",
    "    return \"H\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_final_predicted_df(mnist_df):\n",
    "    mnist_df = mnist_df[[\"P1_mnist_number\",\"P2_mnist_number\",\"P3_mnist_number\",\"P4_mnist_number\",\"P1_mnist_suit\",\"P2_mnist_suit\",\"P3_mnist_suit\",\"P4_mnist_suit\", \"dealer\"]]\n",
    "    \n",
    "    mnist_df[\"P1_mnist_number\"] = mnist_df[\"P1_mnist_number\"].apply(lambda mnist: predict_number_from_mnist(mnist))\n",
    "    mnist_df[\"P2_mnist_number\"] = mnist_df[\"P2_mnist_number\"].apply(lambda mnist: predict_number_from_mnist(mnist))\n",
    "    mnist_df[\"P3_mnist_number\"] = mnist_df[\"P3_mnist_number\"].apply(lambda mnist: predict_number_from_mnist(mnist))\n",
    "    mnist_df[\"P4_mnist_number\"] = mnist_df[\"P4_mnist_number\"].apply(lambda mnist: predict_number_from_mnist(mnist))\n",
    "\n",
    "    mnist_df[\"P1_mnist_suit\"] = mnist_df[\"P1_mnist_suit\"].apply(lambda mnist: predict_suit_from_mnist(mnist))\n",
    "    mnist_df[\"P2_mnist_suit\"] = mnist_df[\"P2_mnist_suit\"].apply(lambda mnist: predict_suit_from_mnist(mnist))\n",
    "    mnist_df[\"P3_mnist_suit\"] = mnist_df[\"P3_mnist_suit\"].apply(lambda mnist: predict_suit_from_mnist(mnist))\n",
    "    mnist_df[\"P4_mnist_suit\"] = mnist_df[\"P4_mnist_suit\"].apply(lambda mnist: predict_suit_from_mnist(mnist))\n",
    "\n",
    "    return mnist_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_df_with_predictions = create_final_predicted_df(mnist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_df_with_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-parliament",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "accessory-contents",
   "metadata": {},
   "source": [
    "### Pipeline: Predict card number and suit for each player as well as dealer (task 1 & 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give coloured image of round\n",
    "# retreive ordered_card_df + dealer_status"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "ada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
