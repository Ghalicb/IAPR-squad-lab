{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_classification import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-mechanism",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-transition",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (28, 28)\n",
    "train_set_size = 60000\n",
    "test_set_size = 10000\n",
    "\n",
    "mnist_folder = os.path.join('data', 'MNIST')\n",
    "\n",
    "train_images_path = os.path.join(mnist_folder, 'train-images-idx3-ubyte.gz')\n",
    "train_labels_path = os.path.join(mnist_folder, 'train-labels-idx1-ubyte.gz')\n",
    "test_images_path = os.path.join(mnist_folder, 't10k-images-idx3-ubyte.gz')\n",
    "test_labels_path = os.path.join(mnist_folder, 't10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "train_images = extract_data(train_images_path, image_shape, train_set_size)\n",
    "test_images = extract_data(test_images_path, image_shape, test_set_size)\n",
    "train_labels = extract_labels(train_labels_path, train_set_size)\n",
    "test_labels = extract_labels(test_labels_path, test_set_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-craps",
   "metadata": {},
   "source": [
    "## Segmented cards from task 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_task0 = os.path.join('data', 'classification_data', 'all_games_classification_series.pickle')\n",
    "df_task0, df_numbers_only, df_not_numbers = load_segmentation_task0(filepath_task0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-domain",
   "metadata": {},
   "source": [
    "## Data loader and augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_aug = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.RandomAffine(degrees=25, scale=(0.8, 1.1), shear=20),\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "augmented_train = augment_data(train_images, transform_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of our DataLoader\n",
    "params = {'batch_size': 128,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Creation of a train/test dataset & dataloader\n",
    "train_merged_images = np.concatenate((train_images, augmented_train))\n",
    "train_merged_labels = np.concatenate((train_labels, train_labels))\n",
    "\n",
    "ds_train = MNISTDataset(train_merged_images, train_merged_labels, transform=transforms.ToTensor())\n",
    "dl_train = data.DataLoader(ds_train, **params)\n",
    "\n",
    "ds_test = MNISTDataset(test_images, test_labels, transform=transforms.ToTensor())\n",
    "dl_test = data.DataLoader(ds_test, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "task0_numbers = np.array([v for v in df_numbers_only.image.apply(preprocess_segmented_task0)])\n",
    "\n",
    "ds_test_task0 = MNISTDataset(task0_numbers, df_numbers_only['rank'].to_numpy().astype(np.int64), \n",
    "                             transform=transforms.ToTensor())\n",
    "dl_test_task0 = data.DataLoader(ds_test_task0, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-wednesday",
   "metadata": {},
   "source": [
    "# Training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-digit",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Net1()\n",
    "model2 = Net2()\n",
    "model3 = Net3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-literature",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "learning_rate = 1e-3\n",
    "opt = torch.optim.Adam(model2.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 7\n",
    "\n",
    "# Train & test our model until convergence\n",
    "for e in range(epochs):\n",
    "    print(f\"Epoch {e+1}\\n-------------------------------\")\n",
    "    train_loop(dl_train, model2, criterion, opt)\n",
    "    test_loop(dl_test, model2, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(dl_test_task0, model2, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:iapr] *",
   "language": "python",
   "name": "conda-env-iapr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
