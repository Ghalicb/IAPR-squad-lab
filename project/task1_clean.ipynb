{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "upset-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_classification import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-mechanism",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-transition",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "elementary-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (28, 28)\n",
    "train_set_size = 60000\n",
    "test_set_size = 10000\n",
    "\n",
    "mnist_folder = os.path.join('data', 'MNIST')\n",
    "\n",
    "train_images_path = os.path.join(mnist_folder, 'train-images-idx3-ubyte.gz')\n",
    "train_labels_path = os.path.join(mnist_folder, 'train-labels-idx1-ubyte.gz')\n",
    "test_images_path = os.path.join(mnist_folder, 't10k-images-idx3-ubyte.gz')\n",
    "test_labels_path = os.path.join(mnist_folder, 't10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "train_images = extract_data(train_images_path, image_shape, train_set_size)\n",
    "test_images = extract_data(test_images_path, image_shape, test_set_size)\n",
    "train_labels = extract_labels(train_labels_path, train_set_size)\n",
    "test_labels = extract_labels(test_labels_path, test_set_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-craps",
   "metadata": {},
   "source": [
    "## Segmented cards from task 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accessible-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_task0 = os.path.join('data', 'classification_data', 'all_games_classification_series_mnist.pickle')\n",
    "df_task0, df_numbers_only, df_not_numbers = load_segmentation_task0(filepath_task0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "associate-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.RandomAffine(degrees=25, scale=(0.7, 1), shear=25),\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "labels_figures = {'J': 10, 'Q': 11, 'K': 12}\n",
    "\n",
    "train_augmented_figs, train_augmented_figs_labels, val_augmented_figs, \\\n",
    "        val_augmented_figs_labels, test_figs, test_figs_labels = \\\n",
    "            get_train_val_test_figures(df_not_numbers, labels_figures, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-domain",
   "metadata": {},
   "source": [
    "## Data loader and augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "seventh-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_aug = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.RandomAffine(degrees=25, scale=(0.8, 1.1), shear=20),\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "augmented_train = augment_data(train_images, transform_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "numerous-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of our DataLoader\n",
    "params = {'batch_size': 128,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Creation of a train/test dataset & dataloader\n",
    "train_merged_images = np.concatenate((train_images, augmented_train, train_augmented_figs))\n",
    "train_merged_labels = np.concatenate((train_labels, train_labels, train_augmented_figs_labels))\n",
    "\n",
    "test_merged_images = np.concatenate((test_images, val_augmented_figs))\n",
    "test_merged_labels = np.concatenate((test_labels, val_augmented_figs_labels)) \n",
    "\n",
    "ds_train = MNISTDataset(train_merged_images, train_merged_labels, transform=transforms.ToTensor())\n",
    "dl_train = data.DataLoader(ds_train, **params)\n",
    "\n",
    "ds_test = MNISTDataset(test_merged_images, test_merged_labels, transform=transforms.ToTensor())\n",
    "dl_test = data.DataLoader(ds_test, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "graduate-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "task0_numbers = np.array([v for v in df_numbers_only.image.apply(img_as_ubyte)])\n",
    "\n",
    "ds_test_task0 = MNISTDataset(task0_numbers, df_numbers_only['rank'].to_numpy().astype(np.int64), \n",
    "                             transform=transforms.ToTensor())\n",
    "dl_test_task0 = data.DataLoader(ds_test_task0, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "moral-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test_task0_figs = MNISTDataset(test_figs, \n",
    "                                  test_figs_labels.astype(np.int64), \n",
    "                                  transform=transforms.ToTensor())\n",
    "dl_test_task0_figs = data.DataLoader(ds_test_task0_figs, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-wednesday",
   "metadata": {},
   "source": [
    "# Training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-digit",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aware-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-literature",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sensitive-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "learning_rate = 1e-3\n",
    "opt = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "guided-mechanism",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "It 1055/1055:\tLoss train: 0.06059, Accuracy train: 97.56%%\n",
      "Test Error:\n",
      "\tAvg loss: 0.00038, Accuracy: 98.29%\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "It 1055/1055:\tLoss train: 0.01649, Accuracy train: 100.00%\n",
      "Test Error:\n",
      "\tAvg loss: 0.00037, Accuracy: 98.43%\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "It 1055/1055:\tLoss train: 0.01611, Accuracy train: 100.00%\n",
      "Test Error:\n",
      "\tAvg loss: 0.00062, Accuracy: 98.07%\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "It 1055/1055:\tLoss train: 0.00509, Accuracy train: 100.00%\n",
      "Test Error:\n",
      "\tAvg loss: 0.00075, Accuracy: 97.96%\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "It 1055/1055:\tLoss train: 0.00857, Accuracy train: 100.00%\n",
      "Test Error:\n",
      "\tAvg loss: 0.00095, Accuracy: 97.77%\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "It 1055/1055:\tLoss train: 0.00703, Accuracy train: 100.00%\n",
      "Test Error:\n",
      "\tAvg loss: 0.00065, Accuracy: 98.17%\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "It 1055/1055:\tLoss train: 0.07759, Accuracy train: 97.56%%\n",
      "Test Error:\n",
      "\tAvg loss: 0.00092, Accuracy: 98.08%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 7\n",
    "\n",
    "# Train & test our model until convergence\n",
    "for e in range(epochs):\n",
    "    print(f\"Epoch {e+1}\\n-------------------------------\")\n",
    "    train_loop(dl_train, model, criterion, opt)\n",
    "    test_loop(dl_test, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "foreign-array",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:\n",
      "\tAvg loss: 0.00931, Accuracy: 82.44%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loop(dl_test_task0, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "flexible-gabriel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:\n",
      "\tAvg loss: 0.02140, Accuracy: 94.44%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loop(dl_test_task0_figs, model, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-fifteen",
   "metadata": {},
   "source": [
    "## Save model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sixth-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = os.path.join('data', 'models')\n",
    "\n",
    "if not os.path.isdir(models_dir):\n",
    "    os.mkdir(models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "removable-conducting",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(models_dir, \"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "muslim-insurance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8,  0,  5, 10, 10,  3,  2,  3,  0,  4,  4,  0,  6,  3,  2,  8,  8,  3,\n",
       "         4,  7,  2,  6,  0,  7, 10,  5,  5,  0,  2,  6, 10,  4,  2,  6,  8,  2,\n",
       "         1,  5,  0,  2,  2,  4, 10,  6, 10,  4,  8,  2,  5,  6,  5,  0,  0,  3,\n",
       "         4, 10,  0,  7,  2,  2,  2,  1,  6,  4,  8,  2,  1,  8,  0,  3,  8,  5,\n",
       "         8,  5,  3,  6,  6,  3,  2,  6,  2,  1,  1,  7,  6,  3,  2,  3,  7,  4,\n",
       "         2,  6,  8,  7,  0,  8,  5,  0,  0,  5,  6,  3,  4,  0, 10,  2,  6,  2,\n",
       "         4,  6,  5,  6,  5,  4,  2,  8,  8,  8,  8,  3,  2,  6,  3,  8,  3,  5,\n",
       "         7,  4,  3,  8,  8,  8,  4,  2,  1,  0, 10,  0,  8,  8,  7,  0,  1,  2,\n",
       "         0,  5,  2,  5,  4, 11,  2,  8,  4,  6,  3,  5,  6,  6,  2,  2,  2,  8,\n",
       "         0,  2,  3,  2,  6,  8,  4,  4,  6,  3,  5,  5,  3,  6,  6,  3,  8,  5,\n",
       "         1,  5,  2,  8,  4,  3,  4,  2,  6,  0, 10,  8,  7,  0,  0, 10,  6,  0,\n",
       "         1,  4,  5,  4,  0,  7,  6, 10,  8,  5,  5,  3,  8,  1,  2,  8, 10,  6,\n",
       "         2,  2,  3, 10,  0,  2,  3, 10,  4,  8,  6,  4,  5,  2,  0,  2,  3,  8,\n",
       "         8,  2,  7,  0,  8,  0,  0,  7,  8,  0,  2,  8,  8,  4, 11,  0,  2,  2,\n",
       "        10,  3,  2,  7,  6,  4,  3,  6,  5,  1,  2,  5,  3, 11,  4, 10,  6,  5,\n",
       "         8,  7,  3,  8,  8,  4,  5,  2,  6])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rank(task0_numbers, Net, \"data/models/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-chemical",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:iapr] *",
   "language": "python",
   "name": "conda-env-iapr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
